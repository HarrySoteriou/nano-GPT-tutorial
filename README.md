# nano-GPT-tutorial
This repository follows the tutorial of Andrej Karpathy on the tiny-Shakespeare dataset. A Transformer Decoder only network that generates Shakespeare-like text, to experiment and improve understanding of Transformer Networks.  
Let's build GPT: from scratch, in code, spelled out.: https://www.youtube.com/watch?v=kCc8FmEb1nY&list=WL&index=6&ab_channel=AndrejKarpathy  
nanogpt-lecture: https://github.com/karpathy/ng-video-lecture

